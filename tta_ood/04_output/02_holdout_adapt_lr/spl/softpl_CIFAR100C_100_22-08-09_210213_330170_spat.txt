[22/08/09 21:02:13] [conf.py:  244]: PyTorch Version: torch=1.8.1+cu102, cuda=10.2, cudnn=7605
[22/08/09 21:02:13] [conf.py:  246]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: 05_ckpt
CORRUPTION:
  CIFAR100C_samples: 100
  CIFAR100_samples: 0
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [1, 2, 3, 4, 5]
  SVHNC_samples: 0
  SVHN_samples: 0
  TYPE: ['spatter']
CUDNN:
  BENCHMARK: True
DATA_DIR: 02_data
DESC: 
LOG_DEST: softpl_CIFAR100C_100_22-08-09_210213_330170_spat.txt
LOG_TIME: 22-08-09_210213_330170
MODEL:
  ADAPTATION: softpl
  ARCH: Standard
  CREATE_EMBEDDINGS: False
  EPISODIC: False
  OOD_METHOD: none
  OOD_THRESHOLD: 0.0
  PL_THRESHOLD: 0.0
N_EPOCHS: 6
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.003
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: 04_output/output_leo
TEST:
  BATCH_SIZE: 200
[22/08/09 21:02:20] [cifar10c.py:  147]: LOADING_TIME: loading cfg and model took 7.3434s
[22/08/09 21:02:20] [cifar10c.py:  170]: test-time adaptation: SOFTPL
[22/08/09 21:02:20] [cifar10c.py:  299]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[22/08/09 21:02:20] [cifar10c.py:  300]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[22/08/09 21:02:20] [cifar10c.py:  301]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0
)
[22/08/09 21:02:20] [cifar10c.py:  183]: resetting model
[22/08/09 21:02:20] [cifar10c.py:  188]: RESET_TIME: resetting model took 0.0035s
[22/08/09 21:02:21] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.453s
[22/08/09 21:05:03] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.7234s
[22/08/09 21:05:03] [cifar10c.py:  241]: epoch 1 error % [spatter1]: 28.34%
[22/08/09 21:05:04] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3474s
[22/08/09 21:07:46] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2449s
[22/08/09 21:07:46] [cifar10c.py:  241]: epoch 2 error % [spatter1]: 49.65%
[22/08/09 21:07:46] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3402s
[22/08/09 21:10:29] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2074s
[22/08/09 21:10:29] [cifar10c.py:  241]: epoch 3 error % [spatter1]: 63.54%
[22/08/09 21:10:29] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3156s
[22/08/09 21:13:11] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.1405s
[22/08/09 21:13:11] [cifar10c.py:  241]: epoch 4 error % [spatter1]: 75.56%
[22/08/09 21:13:11] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3177s
[22/08/09 21:15:54] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2983s
[22/08/09 21:15:54] [cifar10c.py:  241]: epoch 5 error % [spatter1]: 88.92%
[22/08/09 21:15:54] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3278s
[22/08/09 21:18:36] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.0389s
[22/08/09 21:18:36] [cifar10c.py:  241]: epoch 6 error % [spatter1]: 90.00%
[22/08/09 21:18:36] [cifar10c.py:  183]: resetting model
[22/08/09 21:18:36] [cifar10c.py:  188]: RESET_TIME: resetting model took 0.0042s
[22/08/09 21:18:36] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3201s
[22/08/09 21:21:19] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.4043s
[22/08/09 21:21:19] [cifar10c.py:  241]: epoch 1 error % [spatter2]: 32.43%
[22/08/09 21:21:19] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3405s
[22/08/09 21:24:02] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.396s
[22/08/09 21:24:02] [cifar10c.py:  241]: epoch 2 error % [spatter2]: 53.98%
[22/08/09 21:24:02] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3385s
[22/08/09 21:26:45] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3351s
[22/08/09 21:26:45] [cifar10c.py:  241]: epoch 3 error % [spatter2]: 66.56%
[22/08/09 21:26:45] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3472s
[22/08/09 21:29:27] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2763s
[22/08/09 21:29:27] [cifar10c.py:  241]: epoch 4 error % [spatter2]: 78.42%
[22/08/09 21:29:27] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3384s
[22/08/09 21:32:10] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2989s
[22/08/09 21:32:10] [cifar10c.py:  241]: epoch 5 error % [spatter2]: 88.35%
[22/08/09 21:32:10] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3539s
[22/08/09 21:34:52] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3002s
[22/08/09 21:34:52] [cifar10c.py:  241]: epoch 6 error % [spatter2]: 90.00%
[22/08/09 21:34:52] [cifar10c.py:  183]: resetting model
[22/08/09 21:34:52] [cifar10c.py:  188]: RESET_TIME: resetting model took 0.0043s
[22/08/09 21:34:53] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3332s
[22/08/09 21:37:35] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.4522s
[22/08/09 21:37:35] [cifar10c.py:  241]: epoch 1 error % [spatter3]: 36.27%
[22/08/09 21:37:36] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3316s
[22/08/09 21:40:18] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.4126s
[22/08/09 21:40:18] [cifar10c.py:  241]: epoch 2 error % [spatter3]: 57.35%
[22/08/09 21:40:18] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3401s
[22/08/09 21:43:00] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.1462s
[22/08/09 21:43:00] [cifar10c.py:  241]: epoch 3 error % [spatter3]: 68.76%
[22/08/09 21:43:01] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3472s
[22/08/09 21:45:43] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.225s
[22/08/09 21:45:43] [cifar10c.py:  241]: epoch 4 error % [spatter3]: 78.92%
[22/08/09 21:45:43] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3382s
[22/08/09 21:48:26] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.29s
[22/08/09 21:48:26] [cifar10c.py:  241]: epoch 5 error % [spatter3]: 87.66%
[22/08/09 21:48:26] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3607s
[22/08/09 21:51:08] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2767s
[22/08/09 21:51:08] [cifar10c.py:  241]: epoch 6 error % [spatter3]: 89.99%
[22/08/09 21:51:08] [cifar10c.py:  183]: resetting model
[22/08/09 21:51:08] [cifar10c.py:  188]: RESET_TIME: resetting model took 0.0043s
[22/08/09 21:51:09] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3623s
[22/08/09 21:53:51] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.4455s
[22/08/09 21:53:51] [cifar10c.py:  241]: epoch 1 error % [spatter4]: 31.88%
[22/08/09 21:53:51] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3527s
[22/08/09 21:56:34] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3916s
[22/08/09 21:56:34] [cifar10c.py:  241]: epoch 2 error % [spatter4]: 53.81%
[22/08/09 21:56:34] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3427s
[22/08/09 21:59:17] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3362s
[22/08/09 21:59:17] [cifar10c.py:  241]: epoch 3 error % [spatter4]: 65.34%
[22/08/09 21:59:17] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3637s
[22/08/09 22:01:59] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3166s
[22/08/09 22:01:59] [cifar10c.py:  241]: epoch 4 error % [spatter4]: 77.41%
[22/08/09 22:02:00] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3617s
[22/08/09 22:04:42] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3043s
[22/08/09 22:04:42] [cifar10c.py:  241]: epoch 5 error % [spatter4]: 86.64%
[22/08/09 22:04:42] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3706s
[22/08/09 22:07:24] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2215s
[22/08/09 22:07:24] [cifar10c.py:  241]: epoch 6 error % [spatter4]: 90.01%
[22/08/09 22:07:24] [cifar10c.py:  183]: resetting model
[22/08/09 22:07:24] [cifar10c.py:  188]: RESET_TIME: resetting model took 0.0044s
[22/08/09 22:07:25] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3629s
[22/08/09 22:10:07] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3754s
[22/08/09 22:10:07] [cifar10c.py:  241]: epoch 1 error % [spatter5]: 36.85%
[22/08/09 22:10:08] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3708s
[22/08/09 22:12:50] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3866s
[22/08/09 22:12:50] [cifar10c.py:  241]: epoch 2 error % [spatter5]: 55.85%
[22/08/09 22:12:50] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.36s
[22/08/09 22:15:33] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.3345s
[22/08/09 22:15:33] [cifar10c.py:  241]: epoch 3 error % [spatter5]: 68.55%
[22/08/09 22:15:33] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.363s
[22/08/09 22:18:15] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2683s
[22/08/09 22:18:15] [cifar10c.py:  241]: epoch 4 error % [spatter5]: 78.04%
[22/08/09 22:18:16] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.374s
[22/08/09 22:20:58] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.1943s
[22/08/09 22:20:58] [cifar10c.py:  241]: epoch 5 error % [spatter5]: 87.53%
[22/08/09 22:20:58] [cifar10c.py:  228]: OOD_TIME: loading ood data took 0.3713s
[22/08/09 22:23:40] [cifar10c.py:  240]: EPOCH_TIME: running epoch took 162.2201s
[22/08/09 22:23:41] [cifar10c.py:  241]: epoch 6 error % [spatter5]: 89.38%
