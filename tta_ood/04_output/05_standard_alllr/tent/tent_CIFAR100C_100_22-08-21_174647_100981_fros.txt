[22/08/21 17:46:47] [conf.py:  244]: PyTorch Version: torch=1.8.1+cu102, cuda=10.2, cudnn=7605
[22/08/21 17:46:47] [conf.py:  246]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: 05_ckpt
CORRUPTION:
  CIFAR100C_samples: 100
  CIFAR100_samples: 0
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [1, 2, 3, 4, 5]
  SVHNC_samples: 0
  SVHN_samples: 0
  TYPE: ['frost']
CUDNN:
  BENCHMARK: True
DATA_DIR: 02_data
DESC: 
LOG_DEST: tent_CIFAR100C_100_22-08-21_174647_100981_fros.txt
LOG_TIME: 22-08-21_174647_100981
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  CREATE_EMBEDDINGS: False
  EPISODIC: False
  OOD_METHOD: none
  OOD_THRESHOLD: 0.0
  PL_THRESHOLD: 0.0
N_EPOCHS: 3
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.0003
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: 04_output/output_leo
TEST:
  BATCH_SIZE: 200
[22/08/21 17:46:54] [cifar10c.py:  147]: LOADING_TIME: loading cfg and model took 7.284s
[22/08/21 17:46:54] [cifar10c.py:  161]: test-time adaptation: TENT
[22/08/21 17:46:54] [cifar10c.py:  282]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[22/08/21 17:46:54] [cifar10c.py:  283]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[22/08/21 17:46:54] [cifar10c.py:  284]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003
    weight_decay: 0.0
)
[22/08/21 17:46:54] [cifar10c.py:  184]: resetting model
[22/08/21 17:46:54] [cifar10c.py:  189]: RESET_TIME: resetting model took 0.0042s
[22/08/21 17:46:54] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.5813s
[22/08/21 17:49:38] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.9699s
[22/08/21 17:49:38] [cifar10c.py:  242]: epoch 1 error % [frost1]: 8.15%
[22/08/21 17:49:39] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.5612s
[22/08/21 17:52:23] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.7062s
[22/08/21 17:52:23] [cifar10c.py:  242]: epoch 2 error % [frost1]: 8.13%
[22/08/21 17:52:23] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.5909s
[22/08/21 17:55:08] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 164.4015s
[22/08/21 17:55:08] [cifar10c.py:  242]: epoch 3 error % [frost1]: 8.18%
[22/08/21 17:55:08] [cifar10c.py:  184]: resetting model
[22/08/21 17:55:08] [cifar10c.py:  189]: RESET_TIME: resetting model took 0.0039s
[22/08/21 17:55:08] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6001s
[22/08/21 17:57:53] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 164.2755s
[22/08/21 17:57:53] [cifar10c.py:  242]: epoch 1 error % [frost2]: 10.63%
[22/08/21 17:57:53] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6031s
[22/08/21 18:00:37] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 164.1286s
[22/08/21 18:00:37] [cifar10c.py:  242]: epoch 2 error % [frost2]: 10.51%
[22/08/21 18:00:38] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6123s
[22/08/21 18:03:22] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.6472s
[22/08/21 18:03:22] [cifar10c.py:  242]: epoch 3 error % [frost2]: 10.40%
[22/08/21 18:03:22] [cifar10c.py:  184]: resetting model
[22/08/21 18:03:22] [cifar10c.py:  189]: RESET_TIME: resetting model took 0.0041s
[22/08/21 18:03:22] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.5665s
[22/08/21 18:06:06] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.4903s
[22/08/21 18:06:06] [cifar10c.py:  242]: epoch 1 error % [frost3]: 13.31%
[22/08/21 18:06:06] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6041s
[22/08/21 18:08:50] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.5805s
[22/08/21 18:08:50] [cifar10c.py:  242]: epoch 2 error % [frost3]: 13.10%
[22/08/21 18:08:51] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6134s
[22/08/21 18:11:34] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.7504s
[22/08/21 18:11:34] [cifar10c.py:  242]: epoch 3 error % [frost3]: 12.88%
[22/08/21 18:11:34] [cifar10c.py:  184]: resetting model
[22/08/21 18:11:34] [cifar10c.py:  189]: RESET_TIME: resetting model took 0.0039s
[22/08/21 18:11:35] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.5876s
[22/08/21 18:14:19] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.5302s
[22/08/21 18:14:19] [cifar10c.py:  242]: epoch 1 error % [frost4]: 13.62%
[22/08/21 18:14:19] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.64s
[22/08/21 18:17:03] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.8114s
[22/08/21 18:17:03] [cifar10c.py:  242]: epoch 2 error % [frost4]: 13.42%
[22/08/21 18:17:04] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6639s
[22/08/21 18:19:48] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 163.9785s
[22/08/21 18:19:48] [cifar10c.py:  242]: epoch 3 error % [frost4]: 13.27%
[22/08/21 18:19:48] [cifar10c.py:  184]: resetting model
[22/08/21 18:19:48] [cifar10c.py:  189]: RESET_TIME: resetting model took 0.0042s
[22/08/21 18:19:48] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6549s
[22/08/21 18:22:33] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 164.2628s
[22/08/21 18:22:33] [cifar10c.py:  242]: epoch 1 error % [frost5]: 16.87%
[22/08/21 18:22:33] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6742s
[22/08/21 18:25:18] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 164.1635s
[22/08/21 18:25:18] [cifar10c.py:  242]: epoch 2 error % [frost5]: 16.49%
[22/08/21 18:25:18] [cifar10c.py:  229]: OOD_TIME: loading ood data took 0.6563s
[22/08/21 18:28:02] [cifar10c.py:  241]: EPOCH_TIME: running epoch took 164.0459s
[22/08/21 18:28:02] [cifar10c.py:  242]: epoch 3 error % [frost5]: 16.31%
