[22/08/06 19:11:35] [conf.py:  244]: PyTorch Version: torch=1.8.1+cu102, cuda=10.2, cudnn=7605
[22/08/06 19:11:35] [conf.py:  246]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: 05_ckpt
CORRUPTION:
  CIFAR100C_samples: 200
  CIFAR100_samples: 0
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [1, 2, 3, 4, 5]
  SVHNC_samples: 0
  SVHN_samples: 0
  TYPE: ['spatter']
CUDNN:
  BENCHMARK: True
DATA_DIR: 02_data
DESC: 
LOG_DEST: softpl_CIFAR100C_200_22-08-06_191135_929543_spat.txt
LOG_TIME: 22-08-06_191135_929543
MODEL:
  ADAPTATION: softpl
  ARCH: Standard
  CREATE_EMBEDDINGS: False
  EPISODIC: False
  OOD_METHOD: none
  OOD_THRESHOLD: 0.0
  PL_THRESHOLD: 0.0
N_EPOCHS: 6
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: 04_output/output_leo
TEST:
  BATCH_SIZE: 200
[22/08/06 19:11:44] [cifar10c.py:  147]: LOADING_TIME: loading cfg and model took 8.2564s
[22/08/06 19:11:44] [cifar10c.py:  169]: test-time adaptation: SOFTPL
[22/08/06 19:11:44] [cifar10c.py:  298]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[22/08/06 19:11:44] [cifar10c.py:  299]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[22/08/06 19:11:44] [cifar10c.py:  300]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0
)
[22/08/06 19:11:44] [cifar10c.py:  182]: resetting model
[22/08/06 19:11:44] [cifar10c.py:  187]: RESET_TIME: resetting model took 0.0035s
[22/08/06 19:11:45] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.8163s
[22/08/06 19:15:37] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 232.326s
[22/08/06 19:15:37] [cifar10c.py:  240]: epoch 1 error % [spatter1]: 9.16%
[22/08/06 19:15:37] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.5873s
[22/08/06 19:19:52] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 254.498s
[22/08/06 19:19:52] [cifar10c.py:  240]: epoch 2 error % [spatter1]: 25.16%
[22/08/06 19:19:53] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.5803s
[22/08/06 19:24:06] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.5909s
[22/08/06 19:24:06] [cifar10c.py:  240]: epoch 3 error % [spatter1]: 42.08%
[22/08/06 19:24:07] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.5827s
[22/08/06 19:28:21] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 254.358s
[22/08/06 19:28:21] [cifar10c.py:  240]: epoch 4 error % [spatter1]: 56.17%
[22/08/06 19:28:22] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.5915s
[22/08/06 19:32:35] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.8426s
[22/08/06 19:32:35] [cifar10c.py:  240]: epoch 5 error % [spatter1]: 70.68%
[22/08/06 19:32:35] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.5878s
[22/08/06 19:36:48] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.7803s
[22/08/06 19:36:48] [cifar10c.py:  240]: epoch 6 error % [spatter1]: 80.31%
[22/08/06 19:36:48] [cifar10c.py:  182]: resetting model
[22/08/06 19:36:48] [cifar10c.py:  187]: RESET_TIME: resetting model took 0.0042s
[22/08/06 19:36:48] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.5905s
[22/08/06 19:41:02] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.803s
[22/08/06 19:41:02] [cifar10c.py:  240]: epoch 1 error % [spatter2]: 12.70%
[22/08/06 19:41:03] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6176s
[22/08/06 19:45:17] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 254.2542s
[22/08/06 19:45:18] [cifar10c.py:  240]: epoch 2 error % [spatter2]: 23.27%
[22/08/06 19:45:18] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6209s
[22/08/06 19:49:32] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.8174s
[22/08/06 19:49:32] [cifar10c.py:  240]: epoch 3 error % [spatter2]: 41.81%
[22/08/06 19:49:33] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6246s
[22/08/06 19:53:46] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.672s
[22/08/06 19:53:46] [cifar10c.py:  240]: epoch 4 error % [spatter2]: 64.04%
[22/08/06 19:53:47] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6208s
[22/08/06 19:58:00] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.9818s
[22/08/06 19:58:00] [cifar10c.py:  240]: epoch 5 error % [spatter2]: 70.51%
[22/08/06 19:58:01] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.7888s
[22/08/06 20:02:16] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 255.3426s
[22/08/06 20:02:16] [cifar10c.py:  240]: epoch 6 error % [spatter2]: 79.12%
[22/08/06 20:02:16] [cifar10c.py:  182]: resetting model
[22/08/06 20:02:16] [cifar10c.py:  187]: RESET_TIME: resetting model took 0.0041s
[22/08/06 20:02:17] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.616s
[22/08/06 20:06:32] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 255.1058s
[22/08/06 20:06:32] [cifar10c.py:  240]: epoch 1 error % [spatter3]: 16.21%
[22/08/06 20:06:32] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6228s
[22/08/06 20:10:47] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 254.2318s
[22/08/06 20:10:47] [cifar10c.py:  240]: epoch 2 error % [spatter3]: 33.77%
[22/08/06 20:10:47] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6182s
[22/08/06 20:15:00] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.2172s
[22/08/06 20:15:00] [cifar10c.py:  240]: epoch 3 error % [spatter3]: 47.57%
[22/08/06 20:15:01] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6145s
[22/08/06 20:19:14] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.1586s
[22/08/06 20:19:14] [cifar10c.py:  240]: epoch 4 error % [spatter3]: 60.14%
[22/08/06 20:19:15] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6198s
[22/08/06 20:23:27] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.563s
[22/08/06 20:23:27] [cifar10c.py:  240]: epoch 5 error % [spatter3]: 67.26%
[22/08/06 20:23:28] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6272s
[22/08/06 20:27:40] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.2789s
[22/08/06 20:27:40] [cifar10c.py:  240]: epoch 6 error % [spatter3]: 75.11%
[22/08/06 20:27:40] [cifar10c.py:  182]: resetting model
[22/08/06 20:27:40] [cifar10c.py:  187]: RESET_TIME: resetting model took 0.0042s
[22/08/06 20:27:41] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6358s
[22/08/06 20:31:54] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.7481s
[22/08/06 20:31:54] [cifar10c.py:  240]: epoch 1 error % [spatter4]: 12.82%
[22/08/06 20:31:54] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6248s
[22/08/06 20:36:07] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.7505s
[22/08/06 20:36:07] [cifar10c.py:  240]: epoch 2 error % [spatter4]: 32.50%
[22/08/06 20:36:08] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6175s
[22/08/06 20:40:21] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.0317s
[22/08/06 20:40:21] [cifar10c.py:  240]: epoch 3 error % [spatter4]: 51.02%
[22/08/06 20:40:21] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6206s
[22/08/06 20:44:34] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 252.8551s
[22/08/06 20:44:34] [cifar10c.py:  240]: epoch 4 error % [spatter4]: 67.95%
[22/08/06 20:44:35] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6697s
[22/08/06 20:48:48] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.4004s
[22/08/06 20:48:48] [cifar10c.py:  240]: epoch 5 error % [spatter4]: 72.58%
[22/08/06 20:48:49] [cifar10c.py:  227]: OOD_TIME: loading ood data took 0.6138s
[22/08/06 20:53:03] [cifar10c.py:  239]: EPOCH_TIME: running epoch took 253.9793s
[22/08/06 20:53:03] [cifar10c.py:  240]: epoch 6 error % [spatter4]: 76.86%
