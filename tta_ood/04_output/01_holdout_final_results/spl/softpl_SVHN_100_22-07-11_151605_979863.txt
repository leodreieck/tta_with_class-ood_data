[22/07/11 15:16:05] [conf.py:  233]: PyTorch Version: torch=1.8.1+cu102, cuda=10.2, cudnn=7605
[22/07/11 15:16:05] [conf.py:  235]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: 05_ckpt
CORRUPTION:
  CIFAR100C_samples: 0
  CIFAR100_samples: 0
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [1, 2, 3, 4, 5]
  SVHNC_samples: 0
  SVHN_samples: 100
  TYPE: ['saturate']
CUDNN:
  BENCHMARK: True
DATA_DIR: 02_data
DESC: 
LOG_DEST: softpl_SVHN_100_22-07-11_151605_979863.txt
LOG_TIME: 22-07-11_151605_979863
MODEL:
  ADAPTATION: softpl
  ARCH: Standard
  EPISODIC: False
  THRESHOLD: 0.0
N_EPOCHS: 6
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: 04_output/output_leo
TEST:
  BATCH_SIZE: 200
[22/07/11 15:16:15] [cifar10c.py:  118]: test-time adaptation: SOFTPL
[22/07/11 15:16:15] [cifar10c.py:  230]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[22/07/11 15:16:15] [cifar10c.py:  231]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[22/07/11 15:16:15] [cifar10c.py:  232]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0
)
[22/07/11 15:16:15] [cifar10c.py:  128]: resetting model
[22/07/11 15:16:51] [cifar10c.py:  174]: epoch 1 error % [saturate1]: 8.28%
[22/07/11 15:17:26] [cifar10c.py:  174]: epoch 2 error % [saturate1]: 7.99%
[22/07/11 15:18:01] [cifar10c.py:  174]: epoch 3 error % [saturate1]: 7.93%
[22/07/11 15:18:36] [cifar10c.py:  174]: epoch 4 error % [saturate1]: 7.94%
[22/07/11 15:19:11] [cifar10c.py:  174]: epoch 5 error % [saturate1]: 7.94%
[22/07/11 15:19:46] [cifar10c.py:  174]: epoch 6 error % [saturate1]: 8.05%
[22/07/11 15:19:46] [cifar10c.py:  128]: resetting model
[22/07/11 15:20:21] [cifar10c.py:  174]: epoch 1 error % [saturate2]: 10.43%
[22/07/11 15:20:56] [cifar10c.py:  174]: epoch 2 error % [saturate2]: 10.14%
[22/07/11 15:21:31] [cifar10c.py:  174]: epoch 3 error % [saturate2]: 10.28%
[22/07/11 15:22:06] [cifar10c.py:  174]: epoch 4 error % [saturate2]: 9.79%
[22/07/11 15:22:41] [cifar10c.py:  174]: epoch 5 error % [saturate2]: 10.04%
[22/07/11 15:23:16] [cifar10c.py:  174]: epoch 6 error % [saturate2]: 9.82%
[22/07/11 15:23:16] [cifar10c.py:  128]: resetting model
[22/07/11 15:23:50] [cifar10c.py:  174]: epoch 1 error % [saturate3]: 7.79%
[22/07/11 15:24:25] [cifar10c.py:  174]: epoch 2 error % [saturate3]: 7.80%
[22/07/11 15:25:00] [cifar10c.py:  174]: epoch 3 error % [saturate3]: 7.84%
[22/07/11 15:25:35] [cifar10c.py:  174]: epoch 4 error % [saturate3]: 8.17%
[22/07/11 15:26:10] [cifar10c.py:  174]: epoch 5 error % [saturate3]: 8.50%
[22/07/11 15:26:45] [cifar10c.py:  174]: epoch 6 error % [saturate3]: 8.48%
[22/07/11 15:26:45] [cifar10c.py:  128]: resetting model
[22/07/11 15:27:21] [cifar10c.py:  174]: epoch 1 error % [saturate4]: 8.75%
[22/07/11 15:27:56] [cifar10c.py:  174]: epoch 2 error % [saturate4]: 8.89%
[22/07/11 15:28:31] [cifar10c.py:  174]: epoch 3 error % [saturate4]: 9.04%
[22/07/11 15:29:06] [cifar10c.py:  174]: epoch 4 error % [saturate4]: 9.46%
[22/07/11 15:29:41] [cifar10c.py:  174]: epoch 5 error % [saturate4]: 9.34%
[22/07/11 15:30:16] [cifar10c.py:  174]: epoch 6 error % [saturate4]: 9.46%
[22/07/11 15:30:16] [cifar10c.py:  128]: resetting model
[22/07/11 15:30:51] [cifar10c.py:  174]: epoch 1 error % [saturate5]: 10.59%
[22/07/11 15:31:26] [cifar10c.py:  174]: epoch 2 error % [saturate5]: 10.64%
[22/07/11 15:32:00] [cifar10c.py:  174]: epoch 3 error % [saturate5]: 10.86%
[22/07/11 15:32:35] [cifar10c.py:  174]: epoch 4 error % [saturate5]: 11.33%
[22/07/11 15:33:10] [cifar10c.py:  174]: epoch 5 error % [saturate5]: 11.31%
[22/07/11 15:33:45] [cifar10c.py:  174]: epoch 6 error % [saturate5]: 11.43%
